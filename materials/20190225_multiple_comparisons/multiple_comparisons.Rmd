---
title: "Multiple Comparisons (Sleuth3 Sections 6.3 and 6.4)"
output:
  pdf_document:
    fig_height: 2.8
    fig_width: 6
  html_document:
    fig_height: 3
    fig_width: 5
  word_document:
    fig_height: 3
    fig_width: 5
header-includes:
  - \usepackage{booktabs}
geometry: margin=0.6in
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = FALSE)
library(ggplot2)
library(readr)
library(dplyr)
library(gmodels)
```

### Example 1: Diet restriction and longevity in mice (Sleuth3 Case study 5.1.1)

Mice were randomly assigned to one of 6 treatment groups with different diets to investigate relationships between diet and lifetime.  The life span of each mouse was recorded in months.

1. \textbf{NP}: Mice ate as much as they wanted of standard food for lab mice
2. \textbf{N/N85}: Control group.  \textbf{N}: no intervention before weaning; ate as normal. \textbf{N85}: no intervention after weaning; fed weekly diet of 85kcal/week (standard diet for lab mice)
3. \textbf{N/R50}: \textbf{N}: no intervention before weaning. \textbf{R50}: after weaning, restricted diet of 50 kcal/week
4. \textbf{R/R50}: \textbf{R}: restricted diet of 50 kcal/week before weaning. \textbf{R50}: after weaning, restricted diet of 50 kcal/week
5. \textbf{N/R50 lopro}: \textbf{N}: no intervention before weaning. \textbf{R50}: after weaning, restricted diet of 50 kcal/week.  Dietary protein decreased with mouse age.
6. \textbf{N/R40}: \textbf{N}: no intervention before weaning. \textbf{R40}: after weaning, restricted diet of 40 kcal/week

Denote the mean life spans in the population of mice fed each of these diets under laboratory conditions by $\mu_1$ through $\mu_6$.

\textbf{Planned Comparisons:}  Before data were collected, researchers decided on the comparisons below:

\includegraphics[width=0.8\textwidth]{sleuth3_display53.png}

These comparisons determine 5 hypothesis tests:

(a) $H_0: \mu_2 = \mu_3$ vs $H_A: \mu_2 \neq \mu_3$.  Are the population mean lifetimes the same for the \textbf{N/N85} and \textbf{N/R50} groups?

(b) $H_0: \mu_3 = \mu_4$ vs $H_A: \mu_3 \neq \mu_4$.  Are the population mean lifetimes the same for the \textbf{N/R50} and \textbf{R/R50} groups?

(c) $H_0: \mu_3 = \mu_6$ vs $H_A: \mu_3 \neq \mu_6$.  Are the population mean lifetimes the same for the \textbf{N/R50} and \textbf{N/R40} groups?

(d) $H_0: \mu_3 = \mu_5$ vs $H_A: \mu_3 \neq \mu_5$.  Are the population mean lifetimes the same for the \textbf{N/R50} and \textbf{N/R50} lopro groups?

(e) $H_0: \mu_2 = \mu_1$ vs $H_A: \mu_2 \neq \mu_1$.  Are the population mean lifetimes the same for the \textbf{N/N85} and \textbf{NP} groups?

### Example 2: Handicaps and hiring (Sleuth3 Case Study 6.1.1 in Sleuth 3)

A 1990 study conducted a randomized experiment to explore how physical handicaps affect people's perception of employment qualifications.  The researchers prepared five videotaped job interviews using the same two male actors for each.  A set script was designed to reflect an interview with an applicant of average qualifications.  The videos differed only in that the applicant appeared with a different handicap:

 1. in one, he appeared to have no handicap;
 2. in a second, he appeared to have one leg amputated;
 3. in a third, he appeared on crutches;
 4. in a fourth, he appeared to have impaired hearing;
 5. and in a fifth, he appeared in a wheelchair.

Seventy undergraduate students from a US university were randomly assigned to view the videos, fourteen to each video.  After viewing ther video, each subject rated the qualifications of the applicant on a 0 to 10 point applicant qualification scale.

Denote by $\mu_1$ through $\mu_5$ the mean qualification score in the population of ratings that might be given by US undergraduate students from the US university in this study for each of the 5 handicaps groups.

\textbf{"Unplanned" Comparisons}: Maybe we want to compare the mean qualification score for every pair of groups

* $H_0: \mu_1 = \mu_2$ vs $H_A: \mu_1 \neq \mu_2$

* $H_0: \mu_1 = \mu_3$ vs $H_A: \mu_1 \neq \mu_3$

* $H_0: \mu_1 = \mu_4$ vs $H_A: \mu_1 \neq \mu_4$

* $H_0: \mu_1 = \mu_5$ vs $H_A: \mu_1 \neq \mu_5$

* $H_0: \mu_2 = \mu_3$ vs $H_A: \mu_2 \neq \mu_3$

* $H_0: \mu_2 = \mu_4$ vs $H_A: \mu_2 \neq \mu_4$

* $H_0: \mu_2 = \mu_5$ vs $H_A: \mu_2 \neq \mu_5$

* $H_0: \mu_3 = \mu_4$ vs $H_A: \mu_3 \neq \mu_4$

* $H_0: \mu_3 = \mu_5$ vs $H_A: \mu_3 \neq \mu_5$

* $H_0: \mu_4 = \mu_5$ vs $H_A: \mu_4 \neq \mu_5$

There are 10 different comparisons to do.

## Individual Confidence Level vs. Familywise Confidence Level

 * Individual confidence level: the proportion of samples for which a single confidence interval contains the parameter it is estimating
 
 * Familywise confidence level: the proportion of samples for which every one of several different confidence intervals contain the parameters they are estimating

\newpage

### Example (simulation study)

Suppose I have 5 groups with means $\mu_1 = 1$, $\mu_2 = 2$, $\mu_3 = 3$, $\mu_4 = 4$, $\mu_5 = 5$ and standard deviation $\sigma = 1$.

```{r, echo = FALSE, fig.height = 1.25}
x_grid <- seq(from = -2, to = 8, length = 101)
group_sd <- 1

plot_df <- data.frame(
  x = rep(x_grid, 5),
  y = c(dnorm(x_grid, mean = 1, sd = group_sd),
        dnorm(x_grid, mean = 2, sd = group_sd),
        dnorm(x_grid, mean = 3, sd = group_sd),
        dnorm(x_grid, mean = 4, sd = group_sd),
        dnorm(x_grid, mean = 5, sd = group_sd)),
  group = rep(c("Group 1: mean = 1, sd = 1", "Group 2: mean = 2, sd = 1", "Group 3: mean = 3, sd = 1", "Group 4: mean = 4, sd = 1", "Group 5: mean = 5, sd = 1"),
    each = length(x_grid))
)

ggplot(data = plot_df, mapping = aes(x = x, y = y, color = group)) +
  geom_line() +
  theme_bw()
```

\textbf{Results for 1 simulation}

 * Simulated a data set with 100 observations from each of the 5 groups
 * Calculated 95% confidence intervals for differences in group means, for each pair of means (10 intervals total)

\begin{table}[!h]
\centering
\begin{tabular}{c c c c c}
\toprule
Groups & Difference in Means & 95\% CI lower bound & 95\% CI upper bound & Contains true difference? \\
\toprule
2, 1 & 2 - 1 = 1 & 0.99 & 1.54 & Yes \\
\midrule
3, 1 & 3 - 1 = 2 & 1.60 & 2.16 & Yes \\
\midrule
4, 1 & 4 - 1 = 3 & 2.87 & 3.42 & Yes \\
\midrule
5, 1 & 5 - 1 = 4 & 3.55 & 4.10 & Yes \\
\midrule
3, 2 & 3 - 2 = 1 & 0.34 & 0.89 & No \\
\midrule
4, 2 & 4 - 2 = 2 & 1.60 & 2.15 & Yes \\
\midrule
5, 2 & 5 - 2 = 3 & 2.28 & 2.84 & No \\
\midrule
4, 3 & 4 - 3 = 1 & 0.99 & 1.54 & Yes \\
\midrule
5, 3 & 5 - 3 = 2 & 1.67 & 2.22 & Yes \\
\midrule
5, 4 & 5 - 4 = 1 & 0.41 & 0.96 & No \\
\bottomrule
\end{tabular}
\end{table}

For this particular sample, 7 out of 10 of the confidence intervals contain the difference in means they are estimating.

\textbf{Repeated for 1000 simulations:}

 * Repeated the process above for 1000 different simulated data sets.  Table shows:
    * percent of samples for which each CI comparing 2 groups succeded
    * percent of samples for which all 10 CIs succeeded

\begin{table}[!h]
\centering
\begin{tabular}{r l}
\toprule
Groups & Percent of Samples Successful \\
\toprule
2, 1 & 95.1\% \\
\midrule
3, 1 & 94.5\% \\
\midrule
4, 1 & 95.0\% \\
\midrule
5, 1 & 94.5\% \\
\midrule
3, 2 & 95.5\% \\
\midrule
4, 2 & 95.1\% \\
\midrule
5, 2 & 94.8\% \\
\midrule
4, 3 & 94.9\% \\
\midrule
5, 3 & 95.7\% \\
\midrule
5, 4 & 94.4\%\\
\midrule
All 10 comparisons & 71.1\% \\
\bottomrule
\end{tabular}
\end{table}

#### Basic idea: Make individual confidence levels larger to get desired familywise confidence level.

\newpage

## Adjustments for Confidence Intervals

We will discuss just a couple of ideas that are most generally applicable; see the book for many more.

### Reminder of standard procedure

 * In this class, all confidence intervals are calculated as $\text{Estimate} \pm \text{Multiplier} \times SE(\text{Estimate})$
 * So far, the Multiplier is $t_{df}(1 - \alpha/2)$.
    * For a 95% CI, $\alpha = 0.05$, and $1 - \alpha/2 = 0.975$

```{r, fig.height = 2.5, echo = FALSE}
normal_mean <- 0
offset <- qt(0.975, df = 10)
lower <- -4
upper <- 4

plot_df1 <- data.frame(
  x = c(lower,
    seq(from = lower,
      to = normal_mean - offset,
      length = 101),
    normal_mean - offset
    ),
  density = c(0,
    dt(seq(from = lower,
        to = normal_mean - offset,
        length = 101),
      df = 10),
    0)
  )

plot_df2 <- data.frame(
  x = c(upper,
    seq(from = upper,
      to = normal_mean + offset,
      length = 101),
    normal_mean + offset
    ),
  density = c(0,
    dt(seq(from = upper,
        to = normal_mean + offset,
        length = 101),
      df = 10),
    0)
  )


ggplot(mapping = aes(x = c(-4, 4))) +
  geom_polygon(aes(x = x, y = density), fill = "black", alpha = 0.4, data = plot_df1) +
  geom_polygon(aes(x = x, y = density), fill = "black", alpha = 0.4, data = plot_df2) +
  stat_function(fun = dt, args = list(df = 10)) + 
  geom_label(mapping = aes(
    x = c(-3, 0, 3),
    y = c(0.1, 0.1, 0.1),
    label = c("Shaded\nArea\n0.025", "Central\nArea\n0.95", "Shaded\nArea\n0.025")
  )) +
  geom_vline(mapping = aes(xintercept = c(-1*offset, offset))) +
  xlab("") +
  ggtitle(
    expression(paste("Example with ", alpha, " = 0.05 (95% individual CI)")),
    subtitle = "Total area to left of t* is 0.975") +
  scale_x_continuous(name = "",
    breaks = c(-4, -offset, 0, offset, 4),
    labels = c(-4, expression(paste(-t, "*")), 0, expression(paste(t, "*")), 4)) +
  theme_bw()
```

### Bonferroni adjustment

 * If there are $k$ confidence intervals to compute, use $\text{Multiplier} = t_{df}(1 - \alpha/2k)$
 * Example:  Above, we had $k = 10$ confidence intervals

```{r, fig.height = 2.5, echo = FALSE}
normal_mean <- 0
offset <- qt(0.9975, df = 10)
lower <- -4
upper <- 4

plot_df1 <- data.frame(
  x = c(lower,
    seq(from = lower,
      to = normal_mean - offset,
      length = 101),
    normal_mean - offset
    ),
  density = c(0,
    dt(seq(from = lower,
        to = normal_mean - offset,
        length = 101),
      df = 10),
    0)
  )

plot_df2 <- data.frame(
  x = c(upper,
    seq(from = upper,
      to = normal_mean + offset,
      length = 101),
    normal_mean + offset
    ),
  density = c(0,
    dt(seq(from = upper,
        to = normal_mean + offset,
        length = 101),
      df = 10),
    0)
  )

ggplot(mapping = aes(x = c(-4, 4))) +
  geom_polygon(aes(x = x, y = density), fill = "black", alpha = 0.4, data = plot_df1) +
  geom_polygon(aes(x = x, y = density), fill = "black", alpha = 0.4, data = plot_df2) +
  stat_function(fun = dt, args = list(df = 10)) + 
  geom_label(mapping = aes(
    x = c(-3, 0, 3),
    y = c(0.1, 0.1, 0.1),
    label = c("Shaded\nArea\n0.0025", "Central\nArea\n0.995", "Shaded\nArea\n0.0025")
  )) +
  geom_vline(mapping = aes(xintercept = c(-1*offset, offset))) +
  xlab("") +
  ggtitle(
    expression(paste("Example with ", alpha, " = 0.05 (95% familywise CI)")),
    subtitle = "Total area to left of t* is 1 - 0.05/(2 * 10) = 0.9975") +
  scale_x_continuous(name = "",
    breaks = c(-4, -offset, 0, offset, 4),
    labels = c(-4, expression(paste(-t, "*")), 0, expression(paste(t, "*")), 4)) +
  theme_bw()
```

 * Intuition:
    * Each individual CI misses for 0.5% of samples
    * Across all 10, at least one misses for 5% of samples
    * Across all 10, all succeed for 95% of samples

### Scheffe adjustment

 * Use $\text{Multiplier} = \sqrt{(I - 1) F_{(I-1),(n - 1)}(1 - \alpha)}$
 * Generally a larger multiplier (wider CIs) than the Bonferroni adjustment
 * Works for familywise inferences about every possible linear combination of group means $\gamma = C_1 \mu_1 + \cdots + C_I \mu_I$
 * Usually not useful for ANOVA, but very useful for regression models, coming soon!

### R code, Handicaps Study

```{r, message = FALSE}
handicaps <- read_csv("http://www.evanlray.com/data/sleuth3/ex0601_handicaps.csv") %>%
  mutate(
    Handicap = factor(Handicap, levels = c("None", "Amputee", "Crutches", "Hearing", "Wheelchair"))
  )
nrow(handicaps)

head(handicaps)

anova_fit <- lm(Score ~ Handicap, data = handicaps)
```

#### Individual 95% CIs

```{r, echo = FALSE}
options(width = 130)
```

```{r}
fit.contrast(anova_fit, "Handicap", c(-1, 1, 0, 0, 0), conf.int = 0.95)
fit.contrast(anova_fit, "Handicap", c(-1, 0, 1, 0, 0), conf.int = 0.95)
```

...and so on.

Confirming how the CIs were calculated from the estimates and standard errors:

```{r}
t_star <- qt(0.975, df = 70 - 5)
t_star

-0.4714286 - t_star * 0.6171922
-0.4714286 + t_star * 0.6171922

1.021429 - t_star * 0.6171922
1.021429 + t_star * 0.6171922
```

#### Bonferroni 95% familywise CIs

First, find multiplier (note that it's larger!)

```{r}
bonferroni_multiplier <- qt(0.9975, df = 70 - 5)
bonferroni_multiplier
```

```{r}
-0.4714286 - bonferroni_multiplier * 0.6171922
-0.4714286 + bonferroni_multiplier * 0.6171922

1.021429 - bonferroni_multiplier * 0.6171922
1.021429 + bonferroni_multiplier * 0.6171922
```

#### Scheffe 95% familywise CIs

First find the multiplier - note that it's even larger!

```{r}
scheffe_multiplier <- sqrt((5 - 1) * qf(0.95, df1 = 5 - 1, df2 = 70 - 5))
scheffe_multiplier
```

```{r}
-0.4714286 - scheffe_multiplier * 0.6171922
-0.4714286 + scheffe_multiplier * 0.6171922

1.021429 - scheffe_multiplier * 0.6171922
1.021429 + scheffe_multiplier * 0.6171922
```

#### All 10 CIs plotted for each method

```{r, echo = FALSE, warning=FALSE, fig.height = 2.65, fig.width = 7.5}
handicap_levels <- levels(handicaps$Handicap)

ci_results <- data.frame(
  ci_lower = vector("numeric", 30),
  ci_upper = vector("numeric", 30),
  ci_type = vector("character", 30),
  difference = vector("character", 30),
  stringsAsFactors = FALSE
)

bonferroni_multiplier <- qt(0.9975, df = 70 - 5)
scheffe_multiplier <- sqrt((5 - 1) * qf(0.95, df1 = 5 - 1, df2 = 70 - 5))

results_ind <- 0

for(ind1 in 1:4) {
  for(ind2 in (ind1+1):5) {
    c_vec <- rep(0, 5)
    c_vec[ind1] <- -1
    c_vec[ind2] <- 1
    ci <- fit.contrast(anova_fit, "Handicap", c_vec, conf.int = 0.95)
    
    # standard method
    results_ind <- results_ind + 1
    ci_lower <- ci[1, 5]
    ci_upper <- ci[1, 6]
    ci_results[results_ind, "ci_lower"] <- ci_lower
    ci_results[results_ind, "ci_upper"] <- ci_upper
    ci_results[results_ind, "ci_type"] <- "95% Individual"
    ci_results[results_ind, "difference"] <- paste0(handicap_levels[ind2], " - ", handicap_levels[ind1])
    
    # bonferroni
    results_ind <- results_ind + 1
    est <- ci[1, 1]
    se <- ci[1, 2]
    ci_results[results_ind, "ci_lower"] <- est - bonferroni_multiplier * se
    ci_results[results_ind, "ci_upper"] <- est + bonferroni_multiplier * se
    ci_results[results_ind, "ci_type"] <- "95% Familywise,\nBonferroni"
    ci_results[results_ind, "difference"] <- paste0(handicap_levels[ind2], " - ", handicap_levels[ind1])
    
    # scheffe
    results_ind <- results_ind + 1
    est <- ci[1, 1]
    se <- ci[1, 2]
    ci_results[results_ind, "ci_lower"] <- est - scheffe_multiplier * se
    ci_results[results_ind, "ci_upper"] <- est + scheffe_multiplier * se
    ci_results[results_ind, "ci_type"] <- "95% Familywise,\nScheffe"
    ci_results[results_ind, "difference"] <- paste0(handicap_levels[ind2], " - ", handicap_levels[ind1])
  }
}

ci_results$ci_type <- factor(ci_results$ci_type, levels = c("95% Individual", "95% Familywise,\nBonferroni", "95% Familywise,\nScheffe"))

ggplot(data = ci_results) +
  geom_errorbar(mapping = aes(x = difference, ymin = ci_lower, ymax = ci_upper, color = ci_type),
    position = position_dodge()) +
  scale_color_discrete("CI Type") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 50, hjust = 1))
```


## Similar ideas for hypothesis tests

 * p-value = probability of obtaining a test statistic at least as extreme as the value of that statistic we got in our sample data, if $H_0$ is true **in a single test**
    * Provides a measure of strength of evidence against $H_0$ for that test.

 * Imagine that we do 10 hypothesis tests.
 
 * The chance of obtaining a small p-value ("statistically significant result") in at least one of the tests is larger than the chance of obtaining a small p-value in a single test.

#### Idea 1

 * Adjust our standard of evidence (require smaller p-values to believe something is going on)
    * Could do a Bonferroni like adjustment, require 10 times as much evidence for each test if doing 10 tests.
 * In practice
    * Skip calculation of p-values
    * Get familywise confidence intervals for all parameters/comparisons of interest
    * Declare a result "statistically significant" if the familywise CI does not contain hypothesized values

#### Idea 2 (very common, not perfect)

 * Conduct an F test of $H_0: \mu_1 = \mu_2 = \ldots = \mu_I$ vs $H_A:$ at least one mean is different from the others
    * If p-value from the F test is small (say, less than 0.05), proceed to look at individual results, typically using unadjusted intervals/p-values
    * If p-value from the F test is large (say, greater than 0.05), declare no individual results statistically significant, even if some individual t tests had small p-values.

## When to bother?

Opinions differ

 * Book says:
    * if tests are "planned", no need to adjust for multiple comparisons
    * if tests are "unplanned", adjust
 * Some people say you should always adjust for multiple comparisons
 * I say you need to understand the issues and report what you are doing:
    * **Familywise confidence levels can be much less than individual confidence levels**
    * **Report whether or not you have adjusted for multiple comparisons**
    * **Report all confidence intervals/hypothesis tests you perform**, whether or not the results are "statistically significant".  **Reporting only statistically significant results is cheating.**
    * To the extent possible, **plan your analysis before collecting data**, and keep number of planned comparisons small
